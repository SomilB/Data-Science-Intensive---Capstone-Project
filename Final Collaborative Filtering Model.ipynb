{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratings = pd.DataFrame.from_csv('Small/ratings.csv',index_col=None)\n",
    "movies = pd.DataFrame.from_csv('Small/movies.csv',index_col='movieId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20816, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 1: Remove movies prior to August 2003 and with less ratings than the required threshold\n",
    "r = ratings\n",
    "r = r[r.timestamp >= 1059696000] #1059696000 is the UTCTimestamp for Aug 1, 2003 at GMT\n",
    "r = r.set_index('userId')\n",
    "r['user_freq'] = r.index.value_counts() #Generate new column to filter data by: Number of ratings by the user\n",
    "r = r[(r.user_freq <= 2000)&(r.user_freq >= 40)] #Weed out suspect users and those with too few ratings. Lower threshold chosen to ensure user presence in all data partitions.\n",
    "r = r.reset_index()\n",
    "r = r.set_index('movieId') #Generate new column to filter data by: number of ratings per movie\n",
    "r['movie_freq'] = r.index.value_counts()\n",
    "r = r[r.movie_freq >=35] #Filter out movies with too few ratings. Threshold chosen to ensure user presence in all data partitions.\n",
    "r = r.reset_index()\n",
    "r = r.drop(['user_freq','movie_freq','timestamp'],axis=1) #Remove excess data\n",
    "\n",
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Ensuring that the train/test partition produces datasets that pivot to the same dimensions (include all movies and all users).\n",
    "r_piv = r.pivot('movieId','userId','rating')\n",
    "same_shape = False\n",
    "while same_shape == False:\n",
    "    train, test = train_test_split(r, train_size = 0.80) #Randomly partitions data into 80-20 training-test split\n",
    "    trainm = train.pivot('movieId','userId','rating')\n",
    "    testm = test.pivot('movieId','userId','rating')\n",
    "    if (trainm.shape == r_piv.shape) & (testm.shape == r_piv.shape):\n",
    "        same_shape = True\n",
    "\n",
    "k = 4 #Setting k for k-fold cross validation of the training partition\n",
    "n = int(len(train)/k) #Establishing size of each fold (except last) for k-fold cross validation\n",
    "\n",
    "ind = r_piv.index #Storing movieId index for future use\n",
    "col = r_piv.columns #Storing userId column names fof future use\n",
    "nmovies, nusers = r_piv.shape #Store dimensions of the data\n",
    "mu = r_piv.mean(axis = 1) #Store average rating per movie: used in mean normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Ensuring that all k attempts at k-fold validation will use matrices with matching dimensions\n",
    "dim_check = False\n",
    "while dim_check == False:\n",
    "    shuffled_train = train.reindex(np.random.permutation(train.index)) #Randomize order of data (long form)\n",
    "    for num in range(0,k):\n",
    "        #Establish dataset for cross-validation for each k\n",
    "        if num != k-1:\n",
    "            cv = shuffled_train[num*n:(num+1)*n]\n",
    "        else: #Final k may contain different number of entries due to remainder when calculating n\n",
    "            cv = shuffled_train[num*n:]\n",
    "        tr = shuffled_train.drop(cv.index) #Training partition without cross-validation: used to train model for each k\n",
    "        trm = tr.pivot('movieId','userId','rating')\n",
    "        cvm = cv.pivot('movieId','userId','rating')\n",
    "        \n",
    "        #if the dimensions of data matrix for all k values don't match, rerandomize long form data, split, and try again\n",
    "        if (trm.shape != trainm.shape) | (cvm.shape != trainm.shape):\n",
    "            dim_check = False\n",
    "            break #exits for loop early if first few k values don't have matching dimensions\n",
    "        else:\n",
    "            dim_check = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Results = []\n",
    "for trial in range(1,4): #Three trials to account for random nature of feature initialization\n",
    "    for nfeatures in [200,250,300,350,400]: #For loop to optimize for number of features used in final models\n",
    "        for reg in [2.5,5,10]: #For loop to optimize the regularization parameter used in final models\n",
    "            alpha = .003 #learning rate\n",
    "            cum_red = 0 #Stores cumulative reduction in RMSE across all k's when doing cross-validation\n",
    "            for num in range(0,k): #For loop for k-fold cross validation\n",
    "                X = np.random.randn(nmovies,nfeatures) #Random initialization of movie features\n",
    "                Theta = np.random.randn(nusers,nfeatures) #Random initialization of user features\n",
    "                \n",
    "                #Build training and cross-validation matrices for this k\n",
    "                if num != k-1:\n",
    "                    cv = shuffled_train[num*n:(num+1)*n]\n",
    "                else:\n",
    "                    cv = shuffled_train[num*n:]\n",
    "                tr = shuffled_train.drop(cv.index)\n",
    "                trm = tr.pivot('movieId','userId','rating')\n",
    "                cvm = cv.pivot('movieId','userId','rating')\n",
    "                \n",
    "                trm2 = trm.subtract(mu,axis=0) #Mean normalization: so that the regularization drives non-existant ratings towards the mean rating, rather than 0\n",
    "                R = np.asarray(~np.isnan(trm2)) #Matrix containing boolean for rated/not rated for each movie user pairing\n",
    "                trm2 = np.asarray(trm2.fillna(0)) #Replaces missing data with 0's\n",
    "\n",
    "                delta = 1 #Stores change in each iteration's cost function\n",
    "            \n",
    "                J_new = np.sum(np.sum(np.multiply(((np.dot(X,np.transpose(Theta))-trm2)**2),R)))/2 + reg/2*(np.sum(np.sum(Theta**2))+np.sum(np.sum(X**2))) #First initialization of cost function\n",
    "                while delta >= 0.001: #Iterates until cost function changes by < 0.1%\n",
    "                    J_old = J_new\n",
    "                    X_grad = np.dot(np.multiply(np.dot(X,np.transpose(Theta))-trm2,R),Theta) + reg*X #Determine gradient for all movie features\n",
    "                    Theta_grad = np.dot(np.transpose(np.multiply(np.dot(X,np.transpose(Theta))-trm2,R)),X)+reg*Theta #Determine gradient for all user features\n",
    "                    X = X-alpha*X_grad #Movie feature update\n",
    "                    Theta = Theta-alpha*Theta_grad #User feature update\n",
    "                    J_new = np.sum(np.sum(np.multiply(((np.dot(X,np.transpose(Theta))-trm2)**2),R)))/2 + reg/2*(np.sum(np.sum(Theta**2))+np.sum(np.sum(X**2))) #Recalculate cost function\n",
    "                    delta = (J_old-J_new)/J_old #Determine change in cost function\n",
    "                    if delta <0: #If cost function increased, undo the feature updates, reduce learning rate\n",
    "                        X = X+alpha*X_grad #Undoes update to movie features\n",
    "                        Theta = Theta+alpha*Theta_grad #Undoes update to user features\n",
    "                        J_new = J_old\n",
    "                        alpha = alpha/2 #Reduces learning rate by half\n",
    "                        delta=1 #Ensures re-entry into the while loop\n",
    "                \n",
    "                Predictions = pd.DataFrame(data = np.dot(X,np.transpose(Theta)),index = ind, columns = col) #Generate normalized rating predictions: dot product of movie and user features\n",
    "                Predictions = Predictions.add(mu,axis = 0) #Add back mean to undo mean normalization\n",
    "            \n",
    "                RMSE_avg = math.sqrt(np.sum(np.sum((cvm.subtract(mu,axis = 0))**2))/len(cv)) #RMSE of comparison model - give each user the movie's average rating\n",
    "                RMSE_alg = math.sqrt(np.sum(np.sum((Predictions - cvm)**2))/len(cv)) #RMSE of currently trained model\n",
    "                cum_red += (RMSE_avg - RMSE_alg)/RMSE_avg*100 #Adds % reduction in RMSE for this k to running total\n",
    "            \n",
    "            red = cum_red/k #Dividing by k gives the average % rduction in RMSE to be expected from this Trial, number of features, and regularization parameter\n",
    "                        \n",
    "            Results.append({'Trial': trial, 'Features': nfeatures, 'Reg. Parameter': reg, '% Reduction in RMSE': red}) #Store results for future inspection\n",
    "\n",
    "Results = pd.DataFrame(Results)\n",
    "Results = Results.set_index(['Trial','Features','Reg. Parameter'])\n",
    "Results = Results.unstack('Trial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">% Reduction in RMSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Trial</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Features</th>\n",
       "      <th>Reg. Parameter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">200</th>\n",
       "      <th>2.5</th>\n",
       "      <td>5.589384</td>\n",
       "      <td>5.535174</td>\n",
       "      <td>5.445152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>6.840531</td>\n",
       "      <td>6.812381</td>\n",
       "      <td>6.725516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>5.621169</td>\n",
       "      <td>5.664231</td>\n",
       "      <td>5.618512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">250</th>\n",
       "      <th>2.5</th>\n",
       "      <td>5.986714</td>\n",
       "      <td>6.036809</td>\n",
       "      <td>6.181394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>6.849052</td>\n",
       "      <td>6.789370</td>\n",
       "      <td>6.877346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>5.616131</td>\n",
       "      <td>5.642231</td>\n",
       "      <td>5.636288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">300</th>\n",
       "      <th>2.5</th>\n",
       "      <td>6.253209</td>\n",
       "      <td>6.111578</td>\n",
       "      <td>6.361749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>6.972623</td>\n",
       "      <td>7.013077</td>\n",
       "      <td>6.915094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>5.688899</td>\n",
       "      <td>5.635335</td>\n",
       "      <td>5.635817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">350</th>\n",
       "      <th>2.5</th>\n",
       "      <td>5.305559</td>\n",
       "      <td>5.073112</td>\n",
       "      <td>5.030704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>6.324296</td>\n",
       "      <td>6.313873</td>\n",
       "      <td>6.394893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>5.173953</td>\n",
       "      <td>5.226618</td>\n",
       "      <td>5.183267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">400</th>\n",
       "      <th>2.5</th>\n",
       "      <td>5.448427</td>\n",
       "      <td>5.462609</td>\n",
       "      <td>5.276864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>6.242627</td>\n",
       "      <td>6.370354</td>\n",
       "      <td>6.413241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>5.147260</td>\n",
       "      <td>5.249160</td>\n",
       "      <td>5.223585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        % Reduction in RMSE                    \n",
       "Trial                                     1         2         3\n",
       "Features Reg. Parameter                                        \n",
       "200      2.5                       5.589384  5.535174  5.445152\n",
       "         5.0                       6.840531  6.812381  6.725516\n",
       "         10.0                      5.621169  5.664231  5.618512\n",
       "250      2.5                       5.986714  6.036809  6.181394\n",
       "         5.0                       6.849052  6.789370  6.877346\n",
       "         10.0                      5.616131  5.642231  5.636288\n",
       "300      2.5                       6.253209  6.111578  6.361749\n",
       "         5.0                       6.972623  7.013077  6.915094\n",
       "         10.0                      5.688899  5.635335  5.635817\n",
       "350      2.5                       5.305559  5.073112  5.030704\n",
       "         5.0                       6.324296  6.313873  6.394893\n",
       "         10.0                      5.173953  5.226618  5.183267\n",
       "400      2.5                       5.448427  5.462609  5.276864\n",
       "         5.0                       6.242627  6.370354  6.413241\n",
       "         10.0                      5.147260  5.249160  5.223585"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Features  Reg. Parameter\n",
       "200       2.5               5.523237\n",
       "          5.0               6.792809\n",
       "          10.0              5.634637\n",
       "250       2.5               6.068306\n",
       "          5.0               6.838589\n",
       "          10.0              5.631550\n",
       "300       2.5               6.242179\n",
       "          5.0               6.966931\n",
       "          10.0              5.653350\n",
       "350       2.5               5.136458\n",
       "          5.0               6.344354\n",
       "          10.0              5.194613\n",
       "400       2.5               5.395967\n",
       "          5.0               6.342074\n",
       "          10.0              5.206668\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_red = np.mean(Results,axis=1) #averaging results across all Trials\n",
    "avg_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 5.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nfeatures, reg = np.argmax(avg_red) #Determine best pairing of regularization parameter and number of features\n",
    "nfeatures, reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7.322327762639662,\n",
       " 7.496057426963909,\n",
       " 7.559253376952613,\n",
       " 7.316127679573875,\n",
       " 7.358343049990447]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainm2 = trainm.subtract(mu, axis = 0) #Mean normalization of 80% data partition\n",
    "R = np.asarray(~np.isnan(trainm2)) #Matrix containing boolean for rated/not rated for each movie user pairing\n",
    "trainm2 = np.asarray(trainm2.fillna(0)) #Replace missing data with 0's\n",
    "\n",
    "Results = []\n",
    "for num in range(0,5): #Due to random initializations leading to local minima, we need 5 trials so we can report a more accurate % reduction in RMSE\n",
    "    X = np.random.randn(nmovies,nfeatures) #Random initialization of movie features\n",
    "    Theta = np.random.randn(nusers,nfeatures) #Random initialization of user features\n",
    "\n",
    "    alpha = .003 #learning rate\n",
    "\n",
    "    delta = 1 #Stores change in each iteration's cost function\n",
    "    iter = 0 #In case we wish to visualize the decaying magnitude of the cost-function across the upcoming iterations\n",
    "    J = []\n",
    "    J_new = np.sum(np.sum(np.multiply(((np.dot(X,np.transpose(Theta))-trainm2)**2),R)))/2 + reg/2*(np.sum(np.sum(Theta**2))+np.sum(np.sum(X**2))) #First initialization of cost function\n",
    "    J.append({'Iteration': iter, 'Cost': J_new}) #In case we wish to visualize the decaying magnitude of the cost-function across the upcoming iterations\n",
    "    while delta >= 0.001:\n",
    "        J_old = J_new\n",
    "        iter = iter+1\n",
    "        X_grad = np.dot(np.multiply(np.dot(X,np.transpose(Theta))-trainm2,R),Theta) + reg*X #Determine gradients for movie features\n",
    "        Theta_grad = np.dot(np.transpose(np.multiply(np.dot(X,np.transpose(Theta))-trainm2,R)),X)+reg*Theta #Determine gradients for user features\n",
    "        X = X-alpha*X_grad #Movie feature update\n",
    "        Theta = Theta-alpha*Theta_grad #User feature update\n",
    "        J_new = np.sum(np.sum(np.multiply(((np.dot(X,np.transpose(Theta))-trainm2)**2),R)))/2 + reg/2*(np.sum(np.sum(Theta**2))+np.sum(np.sum(X**2))) #Recalculating cost function after the update\n",
    "        J.append({'Iteration': iter, 'Cost': J_new}) #In case we wish to visualize the decaying magnitude of the cost-function across the upcoming iterations\n",
    "        delta = (J_old-J_new)/J_old #Determine change in cost function\n",
    "        if delta <0: #If cost function increased, undo the feature updates, reduce learning rate\n",
    "            X = X+alpha*X_grad\n",
    "            Theta = Theta+alpha*Theta_grad\n",
    "            J_new = J_old\n",
    "            alpha = alpha/2\n",
    "            delta=1\n",
    "                \n",
    "    Predictions = pd.DataFrame(data = np.dot(X,np.transpose(Theta)),index = ind, columns = col) #Generate normalized rating predictions: dot product of movie and user features\n",
    "    Predictions = Predictions.add(mu,axis = 0) #Add back mean to undo mean normalization\n",
    "    \n",
    "    n_obs= len(testm)        \n",
    "    RMSE_avg = math.sqrt(np.sum(np.sum((testm.subtract(mu,axis = 0))**2))/n_obs) #RMSE of comparison model - give each user the movie's average rating\n",
    "    RMSE_alg = math.sqrt(np.sum(np.sum((Predictions - testm)**2))/n_obs) #RMSE of currently trained model\n",
    "    red = (RMSE_avg - RMSE_alg)/RMSE_avg*100 #% reduction in RMSE for this trial\n",
    "            \n",
    "    Results.append(red) #Store results for future inspection\n",
    "\n",
    "Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.4104218592241011"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(Results) #Average % Reduction in RMSE for reporting purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#PCA on movie features: used to make features linearly uncorrelated. Also results in dimensionality reduction and data compression.\n",
    "var_explained = 0\n",
    "iter = 0\n",
    "while var_explained < 0.95: #Want to retain 95% of variance in movie features\n",
    "    iter += 1 #Increase number of components\n",
    "    pca = PCA(n_components=iter)\n",
    "    movie_pca = pd.DataFrame(pca.fit_transform(X), index = ind) #Determine and store principal components for this iteration\n",
    "    var_explained = np.sum(pca.explained_variance_ratio_) #Determine how much of the variance was retained after PCA\n",
    "\n",
    "#PCA on user features: used to make features linearly uncorrelated. Also results in dimensionality reduction and data compression. Goes unused for now.\n",
    "var_explained = 0\n",
    "iter = 0\n",
    "while var_explained < 0.95:\n",
    "    iter += 1\n",
    "    pca = PCA(n_components=iter)\n",
    "    user_pca = pd.DataFrame(pca.fit_transform(Theta), index = col)\n",
    "    var_explained = np.sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Normalize movie features from 0 to 1, a.k.a. Feature Scaling\n",
    "movie_pca_norm = (movie_pca-movie_pca.min(axis = 0))/(movie_pca.max(axis = 0) - movie_pca.min(axis =0))\n",
    "\n",
    "#Store Normalized Euclidean distance from every other movies based on principal components of the learned features\n",
    "dist = []\n",
    "for num1 in range(0,nmovies):\n",
    "    for num2 in range(0,nmovies):\n",
    "        dist.append({'movieId1': ind[num1], 'movieId2': ind[num2], 'distance':math.sqrt(np.sum((movie_pca_norm[movie_pca_norm.index == ind[num1]].values-movie_pca_norm[movie_pca_norm.index == ind[num2]].values)**2))})\n",
    "\n",
    "#Establish easily queriable collection of distances\n",
    "d = pd.DataFrame(dist)\n",
    "d = d.set_index(['movieId1','movieId2'])\n",
    "d = d[d.distance != 0] #Removes pairing that contains 2 instances of the same movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies closest to Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>2.045114</td>\n",
       "      <td>Nightmare Before Christmas, The (1993)</td>\n",
       "      <td>Animation|Children|Fantasy|Musical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40815</th>\n",
       "      <td>2.065060</td>\n",
       "      <td>Harry Potter and the Goblet of Fire (2005)</td>\n",
       "      <td>Adventure|Fantasy|Thriller|IMAX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5816</th>\n",
       "      <td>2.065709</td>\n",
       "      <td>Harry Potter and the Chamber of Secrets (2002)</td>\n",
       "      <td>Adventure|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68237</th>\n",
       "      <td>2.093137</td>\n",
       "      <td>Moon (2009)</td>\n",
       "      <td>Drama|Mystery|Sci-Fi|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>2.097690</td>\n",
       "      <td>Princess Mononoke (Mononoke-hime) (1997)</td>\n",
       "      <td>Action|Adventure|Animation|Drama|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>2.104640</td>\n",
       "      <td>Abyss, The (1989)</td>\n",
       "      <td>Action|Adventure|Sci-Fi|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>2.111250</td>\n",
       "      <td>L.A. Confidential (1997)</td>\n",
       "      <td>Crime|Film-Noir|Mystery|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47610</th>\n",
       "      <td>2.125300</td>\n",
       "      <td>Illusionist, The (2006)</td>\n",
       "      <td>Drama|Fantasy|Mystery|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7458</th>\n",
       "      <td>2.133924</td>\n",
       "      <td>Troy (2004)</td>\n",
       "      <td>Action|Adventure|Drama|War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>2.139426</td>\n",
       "      <td>Lethal Weapon 2 (1989)</td>\n",
       "      <td>Action|Comedy|Crime|Drama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       distance                                           title  \\\n",
       "551    2.045114          Nightmare Before Christmas, The (1993)   \n",
       "40815  2.065060      Harry Potter and the Goblet of Fire (2005)   \n",
       "5816   2.065709  Harry Potter and the Chamber of Secrets (2002)   \n",
       "68237  2.093137                                     Moon (2009)   \n",
       "3000   2.097690        Princess Mononoke (Mononoke-hime) (1997)   \n",
       "1127   2.104640                               Abyss, The (1989)   \n",
       "1617   2.111250                        L.A. Confidential (1997)   \n",
       "47610  2.125300                         Illusionist, The (2006)   \n",
       "7458   2.133924                                     Troy (2004)   \n",
       "2001   2.139426                          Lethal Weapon 2 (1989)   \n",
       "\n",
       "                                         genres  \n",
       "551          Animation|Children|Fantasy|Musical  \n",
       "40815           Adventure|Fantasy|Thriller|IMAX  \n",
       "5816                          Adventure|Fantasy  \n",
       "68237             Drama|Mystery|Sci-Fi|Thriller  \n",
       "3000   Action|Adventure|Animation|Drama|Fantasy  \n",
       "1127           Action|Adventure|Sci-Fi|Thriller  \n",
       "1617           Crime|Film-Noir|Mystery|Thriller  \n",
       "47610             Drama|Fantasy|Mystery|Romance  \n",
       "7458                 Action|Adventure|Drama|War  \n",
       "2001                  Action|Comedy|Crime|Drama  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_mov = 4896 #movieId from example (Harry Potter and the Philosopher's Stone)\n",
    "closest = d.loc[d_mov].sort_values('distance').head(10) #Find 10 'nearest' movies, only contains movieId\n",
    "print(\"Movies closest to %s:\" %movies.loc[d_mov].title)\n",
    "closest = pd.merge(closest,movies,left_index = True, right_index = True).sort_values('distance') #Add title to make the recommendation clearer\n",
    "closest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_ratings = pd.DataFrame.from_csv('My Ratings.csv',index_col='movieId') #Loads my movie ratings\n",
    "my_rat_mean_norm = my_ratings.subtract(mu,axis = 0) #Mean normalization of my ratings\n",
    "R = np.asarray(~np.isnan(my_rat_mean_norm))\n",
    "my_rat_mean_norm = np.asarray(my_rat_mean_norm.fillna(0)) #Replaces missing ratings with 0's\n",
    "my_features = np.random.randn(1,nfeatures) #Random initialization of my user features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Rating</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>5.237571</td>\n",
       "      <td>Shawshank Redemption, The (1994)</td>\n",
       "      <td>Crime|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2959</th>\n",
       "      <td>5.116613</td>\n",
       "      <td>Fight Club (1999)</td>\n",
       "      <td>Action|Crime|Drama|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>5.106159</td>\n",
       "      <td>Usual Suspects, The (1995)</td>\n",
       "      <td>Crime|Mystery|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2571</th>\n",
       "      <td>5.032582</td>\n",
       "      <td>Matrix, The (1999)</td>\n",
       "      <td>Action|Sci-Fi|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48516</th>\n",
       "      <td>5.015751</td>\n",
       "      <td>Departed, The (2006)</td>\n",
       "      <td>Crime|Drama|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>4.956526</td>\n",
       "      <td>Léon: The Professional (a.k.a. The Professiona...</td>\n",
       "      <td>Action|Crime|Drama|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>4.902465</td>\n",
       "      <td>Pulp Fiction (1994)</td>\n",
       "      <td>Comedy|Crime|Drama|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58559</th>\n",
       "      <td>4.837117</td>\n",
       "      <td>Dark Knight, The (2008)</td>\n",
       "      <td>Action|Crime|Drama|IMAX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>4.829178</td>\n",
       "      <td>Princess Mononoke (Mononoke-hime) (1997)</td>\n",
       "      <td>Action|Adventure|Animation|Drama|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68157</th>\n",
       "      <td>4.822656</td>\n",
       "      <td>Inglourious Basterds (2009)</td>\n",
       "      <td>Action|Drama|War</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Predicted Rating                                              title  \\\n",
       "movieId                                                                        \n",
       "318              5.237571                   Shawshank Redemption, The (1994)   \n",
       "2959             5.116613                                  Fight Club (1999)   \n",
       "50               5.106159                         Usual Suspects, The (1995)   \n",
       "2571             5.032582                                 Matrix, The (1999)   \n",
       "48516            5.015751                               Departed, The (2006)   \n",
       "293              4.956526  Léon: The Professional (a.k.a. The Professiona...   \n",
       "296              4.902465                                Pulp Fiction (1994)   \n",
       "58559            4.837117                            Dark Knight, The (2008)   \n",
       "3000             4.829178           Princess Mononoke (Mononoke-hime) (1997)   \n",
       "68157            4.822656                        Inglourious Basterds (2009)   \n",
       "\n",
       "                                           genres  \n",
       "movieId                                            \n",
       "318                                   Crime|Drama  \n",
       "2959                  Action|Crime|Drama|Thriller  \n",
       "50                         Crime|Mystery|Thriller  \n",
       "2571                       Action|Sci-Fi|Thriller  \n",
       "48516                        Crime|Drama|Thriller  \n",
       "293                   Action|Crime|Drama|Thriller  \n",
       "296                   Comedy|Crime|Drama|Thriller  \n",
       "58559                     Action|Crime|Drama|IMAX  \n",
       "3000     Action|Adventure|Animation|Drama|Fantasy  \n",
       "68157                            Action|Drama|War  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = .003 #learning rate for upcoming linear regression\n",
    "\n",
    "#Optimizing linear regression to learn my user features.\n",
    "#No trials required because regardless of the initialization, the result should be a global minimum for that regularization parameter.\n",
    "best_RMSE = 100 #Use RMSE to determine best fit\n",
    "for reg in [1,2.5,5,10]:\n",
    "    delta = 1\n",
    "    J_new = np.sum(np.multiply(((np.dot(X,np.transpose(my_features))-my_rat_mean_norm)**2),R))/2 + reg/2*np.sum(my_features**2) #Linear regression cost function\n",
    "    while delta >= 0.001:\n",
    "        J_old = J_new\n",
    "        iter = iter+1\n",
    "        my_features_grad = np.dot(np.transpose(np.multiply(np.dot(X,np.transpose(my_features))-my_rat_mean_norm,R)),X) + reg*my_features #Gradient for my features\n",
    "        my_features = my_features - alpha*my_features_grad #Update my user features\n",
    "        J_new = np.sum(np.multiply(((np.dot(X,np.transpose(my_features))-my_rat_mean_norm)**2),R))/2 + reg/2*np.sum(my_features**2) #Recalculate cost function\n",
    "        delta = (J_old-J_new)/J_old\n",
    "    my_predictions = pd.DataFrame(data = np.dot(X,np.transpose(my_features)),index = ind) #Generate normalized predictions based on my features\n",
    "    my_predictions = my_predictions.add(mu,axis = 0) #Re-add mean to undo mean normalization\n",
    "    RMSE = np.sqrt(np.sum((my_predictions-my_ratings.values)**2)/np.sum(R)).values #Determine RMSE to compare against other models\n",
    "    #Store best regularization parameter\n",
    "    if RMSE < best_RMSE:\n",
    "        best_RMSE = RMSE\n",
    "        best_reg = reg\n",
    "\n",
    "#Re-determine my features using the best regularization parameter\n",
    "reg = best_reg\n",
    "delta = 1\n",
    "J_new = np.sum(np.multiply(((np.dot(X,np.transpose(my_features))-my_rat_mean_norm)**2),R))/2 + reg/2*np.sum(my_features**2) #Linear regression cost function\n",
    "while delta >= 0.001:\n",
    "    J_old = J_new\n",
    "    iter = iter+1\n",
    "    my_features_grad = np.dot(np.transpose(np.multiply(np.dot(X,np.transpose(my_features))-my_rat_mean_norm,R)),X) + reg*my_features #Gradient for my features\n",
    "    my_features = my_features - alpha*my_features_grad #Update my user features\n",
    "    J_new = np.sum(np.multiply(((np.dot(X,np.transpose(my_features))-my_rat_mean_norm)**2),R))/2 + reg/2*np.sum(my_features**2) #Recalculate cost function\n",
    "    delta = (J_old-J_new)/J_old\n",
    "my_predictions = pd.DataFrame(data = np.dot(X,np.transpose(my_features)),index = ind,columns=['Predicted Rating']) #Generate normalized predictions based on my features\n",
    "my_predictions = my_predictions.add(mu,axis = 0).merge(movies,left_index = True, right_index = True) #Re-add mean to undo mean normalization and add in movie titles\n",
    "my_predictions.sort_values(by='Predicted Rating',ascending=False).head(10) #Sort my predicted ratings in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
